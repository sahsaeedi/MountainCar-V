{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 880
    },
    "colab_type": "code",
    "id": "mXmHZ3wIQycp",
    "outputId": "06fccb8f-7d7b-40fc-efa8-32b9d0096847"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following package was automatically installed and is no longer required:\n",
      "  libnvidia-common-440\n",
      "Use 'apt autoremove' to remove it.\n",
      "Suggested packages:\n",
      "  libgle3\n",
      "The following NEW packages will be installed:\n",
      "  python-opengl\n",
      "0 upgraded, 1 newly installed, 0 to remove and 35 not upgraded.\n",
      "Need to get 496 kB of archives.\n",
      "After this operation, 5,416 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-opengl all 3.1.0+dfsg-1 [496 kB]\n",
      "Fetched 496 kB in 0s (5,012 kB/s)\n",
      "Selecting previously unselected package python-opengl.\n",
      "(Reading database ... 144556 files and directories currently installed.)\n",
      "Preparing to unpack .../python-opengl_3.1.0+dfsg-1_all.deb ...\n",
      "Unpacking python-opengl (3.1.0+dfsg-1) ...\n",
      "Setting up python-opengl (3.1.0+dfsg-1) ...\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following package was automatically installed and is no longer required:\n",
      "  libnvidia-common-440\n",
      "Use 'apt autoremove' to remove it.\n",
      "The following NEW packages will be installed:\n",
      "  xvfb\n",
      "0 upgraded, 1 newly installed, 0 to remove and 35 not upgraded.\n",
      "Need to get 784 kB of archives.\n",
      "After this operation, 2,266 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.4 [784 kB]\n",
      "Fetched 784 kB in 0s (8,795 kB/s)\n",
      "Selecting previously unselected package xvfb.\n",
      "(Reading database ... 146911 files and directories currently installed.)\n",
      "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.4_amd64.deb ...\n",
      "Unpacking xvfb (2:1.19.6-1ubuntu4.4) ...\n",
      "Setting up xvfb (2:1.19.6-1ubuntu4.4) ...\n",
      "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
      "Collecting pyvirtualdisplay\n",
      "  Downloading https://files.pythonhosted.org/packages/d0/8a/643043cc70791367bee2d19eb20e00ed1a246ac48e5dbe57bbbcc8be40a9/PyVirtualDisplay-1.3.2-py2.py3-none-any.whl\n",
      "Collecting EasyProcess\n",
      "  Downloading https://files.pythonhosted.org/packages/48/3c/75573613641c90c6d094059ac28adb748560d99bd27ee6f80cce398f404e/EasyProcess-0.3-py2.py3-none-any.whl\n",
      "Installing collected packages: EasyProcess, pyvirtualdisplay\n",
      "Successfully installed EasyProcess-0.3 pyvirtualdisplay-1.3.2\n",
      "Requirement already satisfied: pyglet in /usr/local/lib/python3.6/dist-packages (1.5.0)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet) (0.16.0)\n"
     ]
    }
   ],
   "source": [
    "!apt-get install python-opengl -y\n",
    "!apt install xvfb -y\n",
    "!pip install pyvirtualdisplay\n",
    "!pip install pyglet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "qa6bHIP7Ub2P",
    "outputId": "75f2ad98-7b5c-465e-e8b3-5ce3af222bf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyVirtualDisplay in /usr/local/lib/python3.6/dist-packages (1.3.2)\n",
      "Requirement already satisfied: EasyProcess in /usr/local/lib/python3.6/dist-packages (from PyVirtualDisplay) (0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install PyVirtualDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "id": "1zPGMSIqSrvB",
    "outputId": "14e0a0c2-b958-4c5b-e79a-bc73a0f4fb19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lpf32S3eStwb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/content/drive/My Drive/NN98/HW7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l-PRDbMSIyzV"
   },
   "outputs": [],
   "source": [
    "os.mkdir('./train3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A3ccPIGfRQej"
   },
   "outputs": [],
   "source": [
    "import matplotlib.animation\n",
    "from IPython.display import HTML\n",
    "from IPython.display import display as ipy_disp\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import gym\n",
    "import random\n",
    "import collections\n",
    "import random\n",
    "import cv2\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eT3ONlDXT5Lk"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import logger as gymlogger\n",
    "from gym.wrappers import Monitor\n",
    "gymlogger.set_level(40) #error only\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "import glob\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "\n",
    "from IPython import display as ipythondisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UYl60Vs0RTXX"
   },
   "outputs": [],
   "source": [
    "def get_screen():\n",
    "  global display\n",
    "  try:\n",
    "    display.stop()\n",
    "  except:\n",
    "    pass\n",
    "  from pyvirtualdisplay import Display\n",
    "  display = Display(visible=0, size=(1400, 900))\n",
    "  display.start()\n",
    "\n",
    "def plot_environment(env, figsize=(5,4)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    img = env.render(mode=\"rgb_array\")\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    return img\n",
    "    \n",
    "get_screen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "58ByRX91Rqs5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "colab_type": "code",
    "id": "Bk_nY3bl_7pi",
    "outputId": "eb52a92b-d6c3-4b13-8758-b4832c95b4b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 0 | reward 200 \n",
      "episode 1 | reward 200 \n",
      "episode 2 | reward 200 \n",
      "episode 3 | reward 200 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-b4214140efbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_from_experience\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maction_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-b4214140efbb>\u001b[0m in \u001b[0;36mcalculate_targets\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0maction_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0maction_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mnext_Q_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0mnext_Q_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdones\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrewards\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscount_factor\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_Q_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    129\u001b[0m           method.__name__))\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1597\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1600\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    844\u001b[0m               *args, **kwds)\n\u001b[1;32m    845\u001b[0m       \u001b[0;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concrete_stateful_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfn_with_cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minner_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class CarAgent:\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "        self.num_actions = 3\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_min = 0.005\n",
    "        self.decay_factor = (self.epsilon - self.epsilon_min) / 2500\n",
    "        self.discount_factor = 0.99                   \n",
    "        self.memory = collections.deque(maxlen=200000) \n",
    "        self.learning_rate = 0.001                  \n",
    "        self.image_width = 84                         \n",
    "        self.image_height = 84                       \n",
    "        self.stack_depth = 4                           \n",
    "        self.model = self.create_CNN_model()           \n",
    "        self.target_model = self.create_CNN_model()    \n",
    "        self.update_target_weights()                   \n",
    "\n",
    "    def create_CNN_model(self):\n",
    "\n",
    "        input_shape = (self.stack_depth, self.image_height, self.image_width)\n",
    "        actions_input = layers.Input((self.num_actions,), name = 'action_mask')\n",
    "\n",
    "        frames_input = layers.Input(input_shape)\n",
    "        conv_1 = layers.Conv2D(32, (8,8), strides=4, padding ='same', activation='relu', kernel_initializer='glorot_uniform',bias_initializer='zeros')(frames_input)\n",
    "        \n",
    "        conv_3 = layers.Conv2D(64, (3,3), strides=1, padding='same', activation='relu',kernel_initializer='glorot_uniform',bias_initializer='zeros')(conv_1)\n",
    "        flatten_1 = layers.Flatten()(conv_3)\n",
    "        \n",
    "        output = layers.Dense(self.num_actions, activation='linear', kernel_initializer='glorot_uniform',bias_initializer='zeros')(flatten_1)\n",
    "        masked_output = layers.Multiply()([output, actions_input])\n",
    "\n",
    "        model = Model([frames_input, actions_input], [masked_output])\n",
    "        optimizer = optimizers.Adam(lr = self.learning_rate)\n",
    "        model.compile(optimizer,loss=keras.losses.huber)\n",
    "        return model\n",
    "\n",
    "    def update_target_weights(self):\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "\n",
    "    def memorize(self, current_state, action, reward, next_state, done):\n",
    "        self.memory.append([current_state, action, reward, next_state, done])\n",
    "\n",
    "    def process_image(self, image):\n",
    "        if len(image.shape) == 3:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        image = cv2.resize(image, (self.image_width, self.image_height))\n",
    "        return image\n",
    "\n",
    "    def greedy_action(self, current_state):\n",
    "        current_state = np.float32(np.true_divide(current_state,255))\n",
    "        action_mask = np.ones((1, self.num_actions))\n",
    "        q_values = self.model.predict([current_state, action_mask])[0]\n",
    "        greedy_action = np.argmax(q_values)\n",
    "\n",
    "        return greedy_action\n",
    "\n",
    "    def calculate_targets(self, batch_size):\n",
    "        current_states = []\n",
    "        rewards = []\n",
    "        actions = []\n",
    "        next_states = []\n",
    "        dones = []\n",
    "        samples = random.sample(self.memory, batch_size)\n",
    "        for sample in samples:\n",
    "            state, action, reward, next_state, done = sample\n",
    "            current_states.append(state)\n",
    "            rewards.append(reward)\n",
    "            actions.append(action)\n",
    "            next_states.append(next_state)\n",
    "            dones.append(done)\n",
    "\n",
    "        current_states = np.array(current_states)\n",
    "        current_states = np.float32(np.true_divide(current_states,255))\n",
    "        next_states = np.array(next_states)\n",
    "        next_states = np.float32(np.true_divide(next_states,255))\n",
    "        action_mask = np.ones((1,self.num_actions))\n",
    "        action_mask = np.repeat(action_mask, batch_size, axis=0)\n",
    "        next_Q_values = self.target_model.predict([next_states, action_mask])\n",
    "        next_Q_values[dones] = 0\n",
    "        targets = rewards + self.discount_factor * np.max(next_Q_values, axis=1)\n",
    "        action_mask_current = self.get_one_hot(actions)\n",
    "\n",
    "        return current_states, action_mask_current, targets\n",
    "\n",
    "    def get_one_hot(self,actions):\n",
    "        actions = np.array(actions)\n",
    "        one_hots = np.zeros((len(actions), self.num_actions))\n",
    "        one_hots[:, 0][np.where(actions == 0)] = 1\n",
    "        one_hots[:,1][np.where(actions == 1)] = 1\n",
    "        one_hots[:, 2][np.where(actions == 2)] = 1\n",
    "        return one_hots\n",
    "\n",
    "    def train_from_experience(self, states, action_mask, targets ):\n",
    "        labels = action_mask * targets[:, None]\n",
    "        loss = self.model.train_on_batch([states, action_mask], labels)\n",
    "\n",
    "    def save_model(self,name):\n",
    "        self.model.save(name)\n",
    "\n",
    "env = gym.make('MountainCar-v0')\n",
    "agent = CarAgent(env)\n",
    "stack_depth = 4\n",
    "seq_memory = collections.deque(maxlen=stack_depth)\n",
    "done = False\n",
    "training = False\n",
    "batch_size = 32\n",
    "update_threshold = 35\n",
    "save_threshold = 100\n",
    "trials = 5000\n",
    "trial_len = 200\n",
    "collect_experience = 1000\n",
    "frame_skip = 4\n",
    "all_rewards = []\n",
    "\n",
    "for episode in range(trials+1):\n",
    "    seq_memory.clear()\n",
    "    initial_state = env.reset()\n",
    "    current_image = env.render(mode = 'rgb_array')\n",
    "    frame = agent.process_image(current_image)\n",
    "    frame = frame.reshape(1, frame.shape[0], frame.shape[1])\n",
    "    current_state = np.repeat(frame, stack_depth, axis=0)\n",
    "    seq_memory.extend(current_state)\n",
    "    episode_reward = 0\n",
    "    for step in range(trial_len):\n",
    "        if step % frame_skip == 0:\n",
    "            if training:\n",
    "                agent.epsilon = agent.epsilon - agent.decay_factor\n",
    "                agent.epsilon = max(agent.epsilon_min, agent.epsilon)\n",
    "            if np.random.rand() <= agent.epsilon:\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                action = agent.greedy_action(current_state.reshape(1, current_state.shape[0]\\\n",
    "                                   , current_state.shape[1], current_state.shape[2]))\n",
    "        next_pos, reward, done, _ = env.step(action)\n",
    "        next_frame = env.render(mode='rgb_array')\n",
    "        next_frame = agent.process_image(next_frame)\n",
    "        seq_memory.append(next_frame)\n",
    "        next_state = np.asarray(seq_memory)\n",
    "        agent.memory.append([current_state, action, reward, next_state, done])\n",
    "        current_state = next_state\n",
    "        if len(agent.memory) == collect_experience:\n",
    "            training = True\n",
    "        if training:\n",
    "            states, action_mask, targets = agent.calculate_targets(batch_size)\n",
    "            agent.train_from_experience(states,action_mask, targets)\n",
    "        if done:\n",
    "            break\n",
    "    all_rewards.append([episode, step+1])\n",
    "    #if episode % 100 == 0:\n",
    "    print(\"episode {} | reward {} \".format(episode, step+1))\n",
    "    if training and (episode % update_threshold) == 0:\n",
    "        agent.update_target_weights()\n",
    "    if training and (episode%save_threshold) == 0:\n",
    "        agent.save_model('./train3/model{}.h5'.format(episode))\n",
    "        pickle.dump(all_rewards, open('./train3/rewards{}.dump'.format(episode), 'wb'))\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1raLQ2tMk91V"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "rewards = pickle.load(open('./train3/rewards900.dump', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "iqY4G5Xd5QWl",
    "outputId": "f2d7362d-f7c1-4cc8-e1dd-c9ced0eb04d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(901, 901)"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "len(rewards), len(np.arange(901))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W3oL3LJf5nKQ"
   },
   "outputs": [],
   "source": [
    "r = [i[1] for i in rewards]\n",
    "t = range(0,len(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "kMGw7gMf6Ke6",
    "outputId": "e2b8c7ab-50c1-4522-9f21-be8fe3591629"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200,\n",
       " 200]"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "qpQSHdt_5CnU",
    "outputId": "30e4c4df-cd4b-4867-a21f-7c980bf10b43"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(r)\n",
    "plt.xlabel(\"Episode\", fontsize=14)\n",
    "plt.ylabel(\"Rewards\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1UxO991g5MRP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MountainCar_CNN(1).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
